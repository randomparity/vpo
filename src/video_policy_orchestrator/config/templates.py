"""Configuration and policy templates for VPO initialization.

This module provides template generation for the `vpo init` command,
creating well-documented configuration files with sensible defaults.
"""

import logging
import os
import tempfile
from dataclasses import dataclass, field
from pathlib import Path

logger = logging.getLogger(__name__)


@dataclass
class InitializationState:
    """Result of checking initialization status.

    Represents the current state of VPO initialization at a given path.
    Used to determine what actions are needed during init.
    """

    data_dir: Path
    """Target data directory path."""

    is_initialized: bool
    """True if config.toml exists (primary indicator of initialization)."""

    config_exists: bool
    """True if config.toml file exists."""

    policies_dir_exists: bool
    """True if policies/ directory exists."""

    plugins_dir_exists: bool
    """True if plugins/ directory exists."""

    default_policy_exists: bool
    """True if policies/default.yaml exists."""

    has_partial_state: bool
    """True if directory exists but is incomplete (interrupted init)."""

    existing_files: list[Path] = field(default_factory=list)
    """List of existing files/directories that would be affected."""


@dataclass
class InitResult:
    """Result of running init command.

    Represents the outcome of an initialization operation,
    tracking what was created, skipped, or failed.
    """

    success: bool
    """True if initialization completed successfully."""

    data_dir: Path
    """Path where initialization occurred."""

    created_files: list[Path] = field(default_factory=list)
    """Files that were created."""

    created_directories: list[Path] = field(default_factory=list)
    """Directories that were created."""

    skipped_files: list[Path] = field(default_factory=list)
    """Files that already existed (with --force, these were overwritten)."""

    error: str | None = None
    """Error message if success is False."""

    dry_run: bool = False
    """True if this was a dry-run (no files actually created)."""


# =============================================================================
# Configuration Template
# =============================================================================


def get_config_template(data_dir: Path) -> str:
    """Generate the configuration template with data_dir-relative paths.

    Args:
        data_dir: The VPO data directory path.

    Returns:
        The config template string with paths relative to data_dir.
    """
    # Compact data_dir for display (use ~ for home directory)
    data_dir_display = str(data_dir).replace(str(Path.home()), "~")
    log_file_path = f"{data_dir_display}/logs/vpo.log"

    return f"""\
# Video Policy Orchestrator Configuration
# Generated by: vpo init
# Documentation: https://github.com/randomparity/vpo
#
# This file controls VPO's behavior. Uncomment and modify settings as needed.
# Environment variables (VPO_*) take precedence over this file.

# =============================================================================
# Tool Paths
# =============================================================================
# Explicit paths to external tools. If not set, VPO searches PATH.
# Environment variable overrides: VPO_FFMPEG_PATH, VPO_FFPROBE_PATH,
# VPO_MKVMERGE_PATH, VPO_MKVPROPEDIT_PATH

[tools]
# ffmpeg = "/usr/local/bin/ffmpeg"
# ffprobe = "/usr/local/bin/ffprobe"
# mkvmerge = "/usr/local/bin/mkvmerge"
# mkvpropedit = "/usr/local/bin/mkvpropedit"

[tools.detection]
# cache_ttl_hours = 24           # How long to cache tool capability info
# auto_detect_on_startup = true  # Detect tools when VPO starts

# =============================================================================
# Behavior
# =============================================================================
# Runtime warnings and suggestions.

[behavior]
# warn_on_missing_features = true   # Warn when features unavailable
# show_upgrade_suggestions = true   # Suggest tool upgrades when outdated

# =============================================================================
# Plugins
# =============================================================================
# Plugin loading and directories.
# Environment variable: VPO_PLUGIN_DIRS (colon-separated paths)

[plugins]
# plugin_dirs = []               # Additional directories to search for plugins
# entry_point_group = "vpo.plugins"  # Entry point group for plugin discovery
# auto_load = true               # Automatically load plugins on startup
# warn_unacknowledged = true     # Warn about unacknowledged directory plugins

# -----------------------------------------------------------------------------
# Metadata Plugins
# -----------------------------------------------------------------------------
# Configure connections to Radarr (movies) and Sonarr (TV series) for
# automatic metadata enrichment during file scans. When configured, VPO
# stores plugin metadata that can be used in policy conditions and actions.
#
# Example policy using plugin metadata:
#   conditional_rules:
#     - name: "Set language from Radarr"
#       when:
#         plugin_metadata:
#           plugin: radarr
#           field: original_language
#           operator: neq
#           value: eng
#       then:
#         - set_language:
#             track_type: audio
#             from_plugin_metadata:
#               plugin: radarr
#               field: original_language

# [plugins.metadata.radarr]
# url = "http://localhost:7878"  # Radarr server URL
# api_key = ""                   # Radarr API key (Settings > General > Security)
# enabled = true                 # Enable/disable this plugin
# timeout_seconds = 30           # API request timeout (1-300)

# [plugins.metadata.sonarr]
# url = "http://localhost:8989"  # Sonarr server URL
# api_key = ""                   # Sonarr API key (Settings > General > Security)
# enabled = true                 # Enable/disable this plugin
# timeout_seconds = 30           # API request timeout (1-300)

# =============================================================================
# Jobs
# =============================================================================
# Background job system settings (transcoding, batch operations).

[jobs]
# retention_days = 30            # Days to keep completed job records
# auto_purge = true              # Purge old jobs on worker start
# temp_directory = ""            # Temp directory for output (empty = source dir)
# backup_original = true         # Keep backup of original after transcode
# log_compression_days = 7       # Days before compressing job log files
# log_deletion_days = 90         # Days before deleting old job logs

# =============================================================================
# Worker
# =============================================================================
# Job worker limits for batch processing.

[worker]
# max_files = 0                  # Max files per worker run (0 = unlimited)
# max_duration = 0               # Max seconds per worker run (0 = unlimited)
# end_by = ""                    # End time in HH:MM format (24h)
# cpu_cores = 0                  # CPU cores for transcoding (0 = auto)

# =============================================================================
# Transcription
# =============================================================================
# Audio transcription and language detection settings.

[transcription]
# plugin = ""                    # Plugin to use (empty = auto-detect)
# model_size = "base"            # Whisper model: tiny, base, small, medium, large
# sample_duration = 30           # Seconds to sample from audio (0 = full track)
# gpu_enabled = true             # Use GPU if available
# max_samples = 3                # Max samples for language detection
# confidence_threshold = 0.85   # Confidence to stop sampling early (0.0-1.0)
# incumbent_bonus = 0.15         # Vote bonus for existing language tag

# =============================================================================
# Logging
# =============================================================================
# Structured logging configuration.

[logging]
level = "info"                   # Log level: debug, info, warning, error
file = "{log_file_path}"         # Log file path (empty = stderr only)
# format = "text"                # Log format: text, json
# include_stderr = false         # Also log to stderr when file is set
# max_bytes = 10485760           # Rotation threshold in bytes (10MB)
# backup_count = 5               # Number of rotated files to keep

# =============================================================================
# Server
# =============================================================================
# Web UI and API server settings for `vpo serve`.
# Environment variable: VPO_AUTH_TOKEN (for authentication)

[server]
# bind = "127.0.0.1"             # Network address to bind to
# port = 8321                    # HTTP port (default: 8321)
# shutdown_timeout = 30.0        # Seconds to wait for graceful shutdown
# auth_token = ""                # Shared secret for HTTP Basic Auth (empty = no auth)

# =============================================================================
# Language
# =============================================================================
# Language code handling and normalization.

[language]
# standard = "639-2/B"           # ISO standard: 639-1, 639-2/B, 639-2/T
# warn_on_conversion = true      # Warn when converting between standards
"""


# =============================================================================
# Default Policy Template
# =============================================================================

DEFAULT_POLICY_TEMPLATE = """\
# Default Policy for Video Policy Orchestrator
# Generated by: vpo init
# Usage: vpo process --policy ~/.vpo/policies/default.yaml [--dry-run] <file.mkv>
#
# This policy provides sensible defaults for organizing track metadata.
# Customize as needed for your library.

schema_version: 1

# Track type ordering (first = top priority)
# Tracks are reordered to match this sequence
track_order:
  - video
  - audio_main
  - audio_alternate
  - subtitle_main
  - subtitle_forced
  - audio_commentary
  - subtitle_commentary
  - attachment

# Preferred audio languages (ISO 639-2 codes)
# First matching language becomes the default audio track
audio_language_preference:
  - eng  # English
  - und  # Undefined/unknown

# Preferred subtitle languages (ISO 639-2 codes)
# Used when set_preferred_subtitle_default is enabled
subtitle_language_preference:
  - eng  # English
  - und  # Undefined/unknown

# Patterns to identify commentary tracks (regex, case-insensitive)
# Tracks matching these patterns are classified as commentary
commentary_patterns:
  - 'commentary'
  - 'director'

# Default flag behavior
default_flags:
  # Set the first video track as default (recommended)
  set_first_video_default: true

  # Set the preferred audio track as default based on language preference
  set_preferred_audio_default: true

  # Set the preferred subtitle track as default (disabled by default)
  # Enable this for foreign-language content where subtitles are expected
  set_preferred_subtitle_default: false

  # Clear the default flag on non-preferred tracks of the same type
  clear_other_defaults: true
"""


# =============================================================================
# Initialization Functions
# =============================================================================


def check_initialization_state(data_dir: Path) -> InitializationState:
    """Check the current initialization state of a VPO data directory.

    Args:
        data_dir: Path to check for VPO initialization.

    Returns:
        InitializationState describing what exists at the path.
    """
    config_path = data_dir / "config.toml"
    policies_dir = data_dir / "policies"
    plugins_dir = data_dir / "plugins"
    default_policy = policies_dir / "default.yaml"

    config_exists = config_path.exists()
    policies_dir_exists = policies_dir.exists()
    plugins_dir_exists = plugins_dir.exists()
    default_policy_exists = default_policy.exists()

    # Directory exists but config doesn't = partial state (interrupted init)
    has_partial_state = (
        data_dir.exists()
        and not config_exists
        and (policies_dir_exists or plugins_dir_exists)
    )

    # Collect existing files for reporting
    existing_files: list[Path] = []
    if config_exists:
        existing_files.append(config_path)
    if policies_dir_exists:
        existing_files.append(policies_dir)
    if plugins_dir_exists:
        existing_files.append(plugins_dir)
    if default_policy_exists:
        existing_files.append(default_policy)

    logger.debug(
        "Initialization state for %s: config=%s, policies=%s, plugins=%s, partial=%s",
        data_dir,
        config_exists,
        policies_dir_exists,
        plugins_dir_exists,
        has_partial_state,
    )

    return InitializationState(
        data_dir=data_dir,
        is_initialized=config_exists,
        config_exists=config_exists,
        policies_dir_exists=policies_dir_exists,
        plugins_dir_exists=plugins_dir_exists,
        default_policy_exists=default_policy_exists,
        has_partial_state=has_partial_state,
        existing_files=existing_files,
    )


def validate_data_dir_path(data_dir: Path) -> str | None:
    """Validate that a path is suitable for a VPO data directory.

    Args:
        data_dir: Path to validate.

    Returns:
        Error message if validation fails, None if valid.
    """
    try:
        # Reject symlinks for security (prevents traversal attacks)
        if data_dir.is_symlink():
            return f"Symlinks are not supported as data directory: {data_dir}"

        # Check if path is a file (can't create directory there)
        if data_dir.exists() and data_dir.is_file():
            return f"A file already exists at this location: {data_dir}"

        # Check parent directory
        parent = data_dir.parent
        if not parent.exists():
            # Try to determine if we can create the parent
            # Walk up to find an existing ancestor
            ancestor = parent
            while not ancestor.exists():
                ancestor = ancestor.parent
                if ancestor == ancestor.parent:
                    # Reached root without finding existing directory
                    return (
                        f"Cannot create directory: no accessible parent for {data_dir}"
                    )

            # Check write permission on existing ancestor
            if not os.access(ancestor, os.W_OK):
                return f"Permission denied: cannot write to {ancestor}"
        else:
            # Parent exists, check write permission
            if not os.access(parent, os.W_OK):
                return f"Permission denied: cannot write to {parent}"

        # If data_dir exists, check write permission
        if data_dir.exists() and not os.access(data_dir, os.W_OK):
            return f"Permission denied: cannot write to {data_dir}"

        return None
    except PermissionError:
        return f"Permission denied: cannot access {data_dir}"
    except OSError as e:
        return f"Cannot access path {data_dir}: {e}"


def _atomic_write_text(path: Path, content: str) -> None:
    """Write content to file atomically using temp file + rename.

    Creates a temp file in the same directory as the target, writes content,
    then atomically replaces the target. This ensures the file is never
    left in a partial state.

    Args:
        path: Target file path.
        content: Content to write.

    Raises:
        OSError: If write or rename fails.
        PermissionError: If permission denied.
    """
    # Create temp file in same directory (ensures same filesystem for atomic rename)
    fd, temp_path_str = tempfile.mkstemp(
        suffix=path.suffix,
        dir=path.parent,
        text=True,
    )
    temp_path = Path(temp_path_str)
    try:
        with os.fdopen(fd, "w") as f:
            f.write(content)
        temp_path.replace(path)  # Atomic on POSIX
    except Exception:
        temp_path.unlink(missing_ok=True)
        raise


def _rollback_init(files: list[Path], dirs: list[Path]) -> None:
    """Clean up created files and directories on failure.

    Removes items in reverse order of creation. Directories are only
    removed if they are empty (to avoid deleting user data).

    Args:
        files: Files that were created.
        dirs: Directories that were created.
    """
    for f in reversed(files):
        try:
            f.unlink(missing_ok=True)
            logger.debug("Rollback: removed file %s", f)
        except OSError as e:
            logger.warning("Rollback: failed to remove file %s: %s", f, e)

    for d in reversed(dirs):
        try:
            if d.exists() and not any(d.iterdir()):
                d.rmdir()
                logger.debug("Rollback: removed directory %s", d)
        except OSError as e:
            logger.warning("Rollback: failed to remove directory %s: %s", d, e)


def create_data_directory(
    data_dir: Path, dry_run: bool = False
) -> tuple[bool, str | None]:
    """Create the VPO data directory.

    Args:
        data_dir: Path where to create the directory.
        dry_run: If True, don't actually create anything.

    Returns:
        Tuple of (success, error_message). Error is None on success.
    """
    if data_dir.exists():
        logger.debug("Data directory already exists: %s", data_dir)
        return True, None

    if dry_run:
        logger.debug("Would create data directory: %s", data_dir)
        return True, None

    try:
        data_dir.mkdir(parents=True, exist_ok=True)
        logger.debug("Created data directory: %s", data_dir)
        return True, None
    except PermissionError:
        return False, f"Permission denied: cannot create {data_dir}"
    except OSError as e:
        return False, f"Cannot create directory {data_dir}: {e}"


def write_config_file(data_dir: Path, dry_run: bool = False) -> tuple[bool, str | None]:
    """Write the config.toml file to the data directory.

    Uses atomic write (temp file + rename) to prevent partial writes.

    Args:
        data_dir: VPO data directory path.
        dry_run: If True, don't actually write anything.

    Returns:
        Tuple of (success, error_message). Error is None on success.
    """
    config_path = data_dir / "config.toml"

    if dry_run:
        logger.debug("Would create config file: %s", config_path)
        return True, None

    try:
        _atomic_write_text(config_path, get_config_template(data_dir))
        logger.debug("Created config file: %s", config_path)
        return True, None
    except PermissionError:
        return False, f"Permission denied: cannot write {config_path}"
    except OSError as e:
        return False, f"Cannot write config file {config_path}: {e}"


def write_default_policy(
    data_dir: Path, dry_run: bool = False
) -> tuple[bool, str | None]:
    """Write the default policy file to the policies directory.

    Uses atomic write (temp file + rename) to prevent partial writes.

    Args:
        data_dir: VPO data directory path.
        dry_run: If True, don't actually write anything.

    Returns:
        Tuple of (success, error_message). Error is None on success.
    """
    policies_dir = data_dir / "policies"
    policy_path = policies_dir / "default.yaml"

    if dry_run:
        logger.debug("Would create policies directory: %s", policies_dir)
        logger.debug("Would create default policy: %s", policy_path)
        return True, None

    try:
        policies_dir.mkdir(parents=True, exist_ok=True)
        logger.debug("Created policies directory: %s", policies_dir)

        _atomic_write_text(policy_path, DEFAULT_POLICY_TEMPLATE)
        logger.debug("Created default policy: %s", policy_path)
        return True, None
    except PermissionError:
        return False, f"Permission denied: cannot write to {policies_dir}"
    except OSError as e:
        return False, f"Cannot create policy file: {e}"


def create_plugins_directory(
    data_dir: Path, dry_run: bool = False
) -> tuple[bool, str | None]:
    """Create the plugins directory.

    Args:
        data_dir: VPO data directory path.
        dry_run: If True, don't actually create anything.

    Returns:
        Tuple of (success, error_message). Error is None on success.
    """
    plugins_dir = data_dir / "plugins"

    if plugins_dir.exists():
        logger.debug("Plugins directory already exists: %s", plugins_dir)
        return True, None

    if dry_run:
        logger.debug("Would create plugins directory: %s", plugins_dir)
        return True, None

    try:
        plugins_dir.mkdir(parents=True, exist_ok=True)
        logger.debug("Created plugins directory: %s", plugins_dir)
        return True, None
    except PermissionError:
        return False, f"Permission denied: cannot create {plugins_dir}"
    except OSError as e:
        return False, f"Cannot create plugins directory: {e}"


def create_logs_directory(
    data_dir: Path, dry_run: bool = False
) -> tuple[bool, str | None]:
    """Create the logs directory.

    Args:
        data_dir: VPO data directory path.
        dry_run: If True, don't actually create anything.

    Returns:
        Tuple of (success, error_message). Error is None on success.
    """
    logs_dir = data_dir / "logs"

    if logs_dir.exists():
        logger.debug("Logs directory already exists: %s", logs_dir)
        return True, None

    if dry_run:
        logger.debug("Would create logs directory: %s", logs_dir)
        return True, None

    try:
        logs_dir.mkdir(parents=True, exist_ok=True)
        logger.debug("Created logs directory: %s", logs_dir)
        return True, None
    except PermissionError:
        return False, f"Permission denied: cannot create {logs_dir}"
    except OSError as e:
        return False, f"Cannot create logs directory: {e}"


def run_init(
    data_dir: Path,
    force: bool = False,
    dry_run: bool = False,
) -> InitResult:
    """Run VPO initialization.

    This is the main orchestration function that coordinates all
    initialization steps. On failure, all created items are rolled back
    to leave a clean state.

    Args:
        data_dir: Path where to initialize VPO.
        force: If True, overwrite existing configuration.
        dry_run: If True, don't actually create anything.

    Returns:
        InitResult describing what was done.
    """
    logger.debug(
        "Running init: data_dir=%s, force=%s, dry_run=%s",
        data_dir,
        force,
        dry_run,
    )

    # Validate the path first
    validation_error = validate_data_dir_path(data_dir)
    if validation_error:
        return InitResult(
            success=False,
            data_dir=data_dir,
            error=validation_error,
            dry_run=dry_run,
        )

    # Check current state
    state = check_initialization_state(data_dir)

    # Handle already-initialized case
    if state.is_initialized and not force:
        return InitResult(
            success=False,
            data_dir=data_dir,
            skipped_files=state.existing_files,
            error=(
                f"VPO is already initialized at {data_dir}. Use --force to overwrite."
            ),
            dry_run=dry_run,
        )

    # Track what we plan to create (for result reporting)
    planned_files: list[Path] = []
    planned_directories: list[Path] = []
    skipped_files: list[Path] = []

    # Track what was ACTUALLY created (for rollback)
    actually_created_files: list[Path] = []
    actually_created_dirs: list[Path] = []

    def handle_failure(error_msg: str) -> InitResult:
        """Roll back and return failure result."""
        if not dry_run:
            _rollback_init(actually_created_files, actually_created_dirs)
            error_msg = f"{error_msg} All changes have been rolled back."
        return InitResult(
            success=False,
            data_dir=data_dir,
            error=error_msg,
            dry_run=dry_run,
        )

    # Create data directory
    data_dir_existed = data_dir.exists()
    success, error = create_data_directory(data_dir, dry_run)
    if not success:
        return handle_failure(error or "Failed to create data directory.")
    if not data_dir_existed:
        planned_directories.append(data_dir)
        if not dry_run:
            actually_created_dirs.append(data_dir)

    # Create logs directory
    logs_dir = data_dir / "logs"
    logs_dir_existed = logs_dir.exists()
    if logs_dir_existed:
        skipped_files.append(logs_dir)

    success, error = create_logs_directory(data_dir, dry_run)
    if not success:
        return handle_failure(error or "Failed to create logs directory.")
    if not logs_dir_existed:
        planned_directories.append(logs_dir)
        if not dry_run:
            actually_created_dirs.append(logs_dir)

    # Write config file
    config_path = data_dir / "config.toml"
    config_existed = config_path.exists()
    if config_existed:
        skipped_files.append(config_path)
    success, error = write_config_file(data_dir, dry_run)
    if not success:
        return handle_failure(error or "Failed to write config file.")
    planned_files.append(config_path)
    if not dry_run and not config_existed:
        actually_created_files.append(config_path)

    # Create policies directory and default policy
    policies_dir = data_dir / "policies"
    policy_path = policies_dir / "default.yaml"
    policies_dir_existed = policies_dir.exists()
    policy_existed = policy_path.exists()

    if policies_dir_existed:
        skipped_files.append(policies_dir)
    if policy_existed:
        skipped_files.append(policy_path)

    success, error = write_default_policy(data_dir, dry_run)
    if not success:
        return handle_failure(error or "Failed to write default policy.")
    if not policies_dir_existed:
        planned_directories.append(policies_dir)
        if not dry_run:
            actually_created_dirs.append(policies_dir)
    planned_files.append(policy_path)
    if not dry_run and not policy_existed:
        actually_created_files.append(policy_path)

    # Create plugins directory
    plugins_dir = data_dir / "plugins"
    plugins_dir_existed = plugins_dir.exists()
    if plugins_dir_existed:
        skipped_files.append(plugins_dir)

    success, error = create_plugins_directory(data_dir, dry_run)
    if not success:
        return handle_failure(error or "Failed to create plugins directory.")
    if not plugins_dir_existed:
        planned_directories.append(plugins_dir)
        if not dry_run:
            actually_created_dirs.append(plugins_dir)

    logger.debug(
        "Init completed: created %d files, %d directories",
        len(planned_files),
        len(planned_directories),
    )

    return InitResult(
        success=True,
        data_dir=data_dir,
        created_files=planned_files,
        created_directories=planned_directories,
        skipped_files=skipped_files,
        dry_run=dry_run,
    )
